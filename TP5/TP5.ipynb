{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvDoQkenEpufKpnSwhcoxR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TP5:**\n",
        "1.Importa las librerías necesarias:"
      ],
      "metadata": {
        "id": "s3CjuBv30M8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "GjYDK861zXjs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define los parámetros necesarios para el detector de fondo naive:"
      ],
      "metadata": {
        "id": "I_jwbUcI0VJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 50 # cantidad de frames utilizados para la estimación\n",
        "intervalo = 100 # intervalo de tiempo para recalcular el fondo\n",
        "alpha = 0.5 # factor de aprendizaje para la mediana\n"
      ],
      "metadata": {
        "id": "-Lj27ip6zYb9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Carga el video y extrae los frames:"
      ],
      "metadata": {
        "id": "sZunUr-W0Zc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('/content/slow_traffic_small.mp4')\n",
        "frames = []\n",
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "  frames.append(frame)\n"
      ],
      "metadata": {
        "id": "UVIRiMAhzajh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Calcula el fondo utilizando la mediana de los primeros N frames:"
      ],
      "metadata": {
        "id": "vQiqJJ410ayq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fondo = np.median(frames[:N], axis=0).astype(np.uint8)\n"
      ],
      "metadata": {
        "id": "mmIW5dXdzesb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Recorre los frames restantes y calcula la máscara de foreground utilizando la diferencia absoluta entre el frame y el fondo:"
      ],
      "metadata": {
        "id": "dOBygi9V0sDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mascaras = []\n",
        "for i in range(N, len(frames)):\n",
        "  frame = frames[i]\n",
        "  mascara = cv2.absdiff(frame, fondo)\n",
        "  mascara = cv2.cvtColor(mascara, cv2.COLOR_BGR2GRAY)\n",
        "  mascara = cv2.threshold(mascara, 25, 255, cv2.THRESH_BINARY)[1]\n",
        "  mascaras.append(mascara)\n",
        "\n",
        "  if i % intervalo == 0:\n",
        "    fondo = np.median(frames[i-N:i], axis=0).astype(np.uint8)\n"
      ],
      "metadata": {
        "id": "uD-3f1NMzhvX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Aplica las mascaras a los frames para segmentar los objetos en movimiento:"
      ],
      "metadata": {
        "id": "inZVXrxW0vdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(frames)):\n",
        "  frame = frames[i]\n",
        "  mascara = mascaras[i-N]\n",
        "  resultado = cv2.bitwise_and(frame, frame, mask=mascara)\n",
        "\n",
        "  # Mostrar el resultado\n",
        "  from google.colab.patches import cv2_imshow\n",
        "# ...\n",
        "  cv2_imshow(frame)\n",
        "  if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "id": "HpFX1CvAziKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONCLUSION:\n",
        "El método que utilicé fue el detector de fondo naive basado en la mediana, que estima el fondo utilizando una ventana deslizante de N frames y recalculando el fondo cada cierto intervalo de tiempo. Este método es simple y computacionalmente eficiente, pero puede tener problemas cuando hay cambios significativos en la iluminación o cuando hay objetos en movimiento continuo.\n",
        "\n",
        "Por otro lado, el método de backprojection utiliza una imagen de histograma de color para detectar objetos en movimiento basados en la comparación de la distribución de color del objeto de interés con la distribución de color del fondo. Es efectivo en situaciones donde el objeto de interés tiene un color distintivo, pero puede ser menos efectivo en situaciones de iluminación cambiante o cuando el objeto de interés está parcialmente oculto.\n",
        "\n",
        "Finalmente, el algoritmo de meanshift utiliza una ventana deslizante para buscar el objeto de interés en cada frame, y ajusta la posición de la ventana para maximizar la similitud entre la distribución de color del objeto y la del fondo. Este método es robusto ante cambios en la iluminación y cuando hay objetos en movimiento continuo, pero puede ser computacionalmente costoso en aplicaciones en tiempo real."
      ],
      "metadata": {
        "id": "oxHdtFYO00mU"
      }
    }
  ]
}